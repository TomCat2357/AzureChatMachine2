# %%

import streamlit as st
import logging, traceback
from logging.handlers import TimedRotatingFileHandler

def initialize_logger():
    """ ãƒ­ã‚¬ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹é–¢æ•° """
    # ãƒ­ã‚¬ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—ã¾ãŸã¯ä½œæˆã—ã¾ã™
    logger = logging.getLogger(__name__)
    # ãƒ­ã‚¬ãƒ¼ã®ãƒ¬ãƒ™ãƒ«ã‚’DEBUGã«è¨­å®šã—ã¾ã™
    logger.setLevel(logging.DEBUG)

    # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è¨­å®šã—ã¾ã™
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¸ã®ãƒãƒ³ãƒ‰ãƒ©ã‚’ä½œæˆã—ã€è¨­å®šã—ã¾ã™
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.DEBUG)
    console_handler.setFormatter(formatter)

    # ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒãƒ³ãƒ‰ãƒ©ã‚’ä½œæˆã—ã€è¨­å®šã—ã¾ã™
    file_handler = TimedRotatingFileHandler("../../log/streamlit_logfile.log", when="midnight", interval=1, backupCount=7)
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(formatter)
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ—¥ä»˜å½¢å¼ã‚’è¨­å®šã—ã¾ã™
    file_handler.suffix = "%Y-%m-%d"

    # ãƒ­ã‚¬ãƒ¼ã«ãƒãƒ³ãƒ‰ãƒ©ã‚’è¿½åŠ ã—ã¾ã™
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

    return logger
# Streamlitã®session_stateã‚’ä½¿ã£ã¦ãƒ­ã‚¬ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚ŒãŸã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
if 'logger_initialized' not in st.session_state:
    logger = initialize_logger()
    st.session_state['logger_initialized'] = True
else:
    logger = logging.getLogger(__name__)    

from typing import Any, List, Generator, Iterable
import openai, os, redis, time, json, tiktoken, datetime, requests
import numpy as np
from threading import Thread
from queue import Queue, Empty
from copy import copy, deepcopy
from concurrent.futures import ThreadPoolExecutor

executor1 = ThreadPoolExecutor(1)

redisCliPrompt = redis.Redis(host="redis_6379", port=6379, db=0)
redisCliUserSetting = redis.Redis(host="redis_6379", port=6379, db=1)
redisCliPastChat = redis.Redis(host="redis_6379", port=6379, db=2)
redisCliAccessTime = redis.Redis(host="redis_6379", port=6379, db=3)

logger.info("start")

def seconds_since_midnight() -> int:
    t = time.localtime()
    return t.tm_hour * 3600 + t.tm_min * 60 + t.tm_sec


def get_day_str(day: datetime.date = None, days_delta: int = 0) -> str:
    if not (day):
        day = datetime.date.today()
    if days_delta:
        day += datetime.timedelta(days=days_delta)
    return day.isoformat().split("T")[0]


def trim_tokens(
    messages: List[dict], max_tokens: int, model_name: str = "gpt-3.5-turbo-0301"
) -> List[dict]:
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒæŒ‡å®šã—ãŸæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¶…ãˆã‚‹å ´åˆã€
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å…ˆé ­ã‹ã‚‰é †ã«å‰Šé™¤ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ä»¥ä¸‹ã«ä¿ã¤ã€‚

    å¼•æ•°:
        messages (List[dict]): ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆã€‚
        max_tokens (int): æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã€‚
        model_name (str): ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯'gpt-3.5-turbo-0301'ï¼‰ã€‚

    æˆ»ã‚Šå€¤:
        List[dict]: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ä»¥ä¸‹ã«ãªã£ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆã€‚
    """
    # ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹
    while True:
        # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
        total_tokens = calc_token_tiktoken(str(messages), model_name=model_name)
        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ä»¥ä¸‹ã«ãªã£ãŸå ´åˆã€ãƒ«ãƒ¼ãƒ—ã‚’çµ‚äº†
        if total_tokens <= max_tokens:
            break
        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å…ˆé ­ã‚’å‰Šé™¤
        messages.pop(0)

    # ä¿®æ­£ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¿½ï¿½ï¿½ãƒªã‚¹ãƒˆã‚’è¿”ã™
    return messages


def response_chatgpt(
    prompt: List[dict], model_name: str = "gpt-3.5-turbo"
) -> Generator:
    """
    ChatGPTã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚

    å¼•æ•°:
        prompt (List[dict]): éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå…¥ã£ãŸãƒªã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚
        model_name (str): ä½¿ç”¨ã™ã‚‹ChatGPTã®ãƒ¢ãƒ‡ãƒ«åã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯"gpt-3.5-turbo"ã€‚

    æˆ»ã‚Šå€¤:
        response: ChatGPTã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€‚
    """
    # logger.debug(role(user_msg))
    logger.debug(f"trim_tokenså‰ã®prompt: {prompt}")
    logger.debug(f"trim_tokenså‰ã®promptã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {calc_token_tiktoken(str(prompt))}")
    # logger.debug(f"trim_tokenså‰ã®messages_role: {type(messages)}")

    prompt = trim_tokens(prompt, INPUT_MAX_TOKENS)
    logger.debug(f"trim_tokenså¾Œã®prompt: {str(prompt)}")
    logger.debug(f"trim_tokenså¾Œã®promptã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {calc_token_tiktoken(str(prompt))}")
    response = openai.ChatCompletion.create(
        model=model_name, messages=prompt, stream=True
    )
    return response


def calc_token_tiktoken(
    chat: str, encoding_name: str = "", model_name: str = "gpt-3.5-turbo-0301"
) -> int:
    """
    # å¼•æ•°ã®èª¬æ˜:
    # chat: ãƒˆãƒ¼ã‚¯ï¿½ï¿½æ•°ã‚’è¨ˆç®—ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã€‚ã“ã®ãƒ†ã‚­ã‚¹ãƒˆãŒAIãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã©ã®ã‚ˆã†ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã‹ã‚’åˆ†æã—ã¾ã™ã€‚

    # encoding_name: ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®åå‰ã€‚ã“ã®å¼•æ•°ã‚’æŒ‡å®šã™ã‚‹ã¨ã€ãã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
    # ä¾‹ãˆã° 'utf-8' ã‚„ 'ascii' ãªã©ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åã‚’æŒ‡å®šã§ãã¾ã™ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯ã€model_nameã«åŸºã¥ã„ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒé¸ã°ã‚Œã¾ã™ã€‚

    # model_name: ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã®åå‰ã€‚ã“ã®å¼•æ•°ã¯ã€ç‰¹å®šã®AIãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•ã§é¸æŠã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
    # ä¾‹ãˆã° 'gpt-3.5-turbo-0301' ã¨ã„ã†ãƒ¢ãƒ‡ãƒ«åã‚’æŒ‡å®šã™ã‚Œã°ã€ãã®ãƒ¢ãƒ‡ãƒ«ã«é©ã—ãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒé¸ã°ã‚Œã¾ã™ã€‚
    # encoding_nameãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ã€ã“ã®å¼•æ•°ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
    """
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ±ºå®šã™ã‚‹
    if encoding_name:
        # encoding_nameãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ã€ãã®åå‰ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—ã™ã‚‹
        encoding = tiktoken.get_encoding(encoding_name)
    elif model_name:
        # model_nameãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ã€ãã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—ã™ã‚‹
        encoding = tiktoken.get_encoding(tiktoken.encoding_for_model(model_name).name)
    else:
        # ä¸¡æ–¹ã¨ã‚‚æŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ã‚‹
        raise ValueError("Both encoding_name and model_name are missing.")

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã«å¤‰æ›ã—ã€ãã®æ•°ã‚’æ•°ãˆã‚‹
    num_tokens = len(encoding.encode(chat))
    return num_tokens


def check_rate_limit_exceed(
    redis_client: redis.Redis,
    key_name: str = "access",
    late_limit: int = 1,
    late_limit_period: float = 1.0,
) -> bool:
    """
    Checks if the rate limit exceeds for a given period.

    Args:
        redis_client (redis.Redis): The Redis client object.
        key_name : Redis client key name.
        late_limit (int, optional): The maximum number of access data within a certain period. Defaults to 1.
        late_limit_period (float, optional): The period in seconds. If the number of access data within this period is less than `late_limit`, the data from the previous day is also retrieved. Defaults to 1.0.

    Returns:
        bool: True if the rate limit is exceeded, False otherwise.
    """
    # Get the current timestamp
    now = time.time()
    # Retrieve the access data for the current date from the Redis client
    access_data = redis_client.zrangebyscore(
        key_name,
        now - late_limit_period,
        "+inf",
    )

    # Log the number of past access data
    logger.debug(f"Number of past access data: {len(access_data)}")
    # If the number of access data is less than the late limit, return False
    if len(access_data) < late_limit:
        return False
    # Otherwise, return True
    else:
        return True


# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’è¿½åŠ 
def add_redis_chat_log(response, index):
    for chunk in response:
        tmp_assistant_msg = chunk["choices"][0]["delta"].get("content", "")
        assistant_prompt = json.loads(redisCliPrompt.lindex(st.session_state.id, index))
        assistant_prompt["content"] += tmp_assistant_msg
        redisCliPrompt.lset(st.session_state.id, index, json.dumps(assistant_prompt))


class MultiGenerator:
    def __init__(self, generator: Generator = None):
        """ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‹ã‚‰è¤‡æ•°ã®ã‚­ãƒ¥ãƒ¼ã«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹ã€‚"""
        if generator is not None:
            self.generator = generator

    def set_generator(self, generator: Generator):
        self.generator = generator

    def queue_push_forever(self) -> None:
        """ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ç„¡é™ã«ã‚­ãƒ¥ãƒ¼ã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã€‚"""
        for chunk in self.generator:
            for q in self.queues:
                q.put(chunk)

    def threading_queue_push_forever(self) -> None:
        """`queue_push_forever` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã€‚"""
        Thread(target=self.queue_push_forever).start()

    def queue_push(self) -> None:
        """ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‹ã‚‰æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€å…¨ã¦ã®ã‚­ãƒ¥ãƒ¼ã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã€‚"""
        chunk = next(self.generator)
        for q in self.queues:
            q.put(chunk)

    def get_queue_generators(
        self, queues_num: int = 1, timeout: float = 5
    ) -> List[Generator[Any, None, None]]:
        """æŒ‡å®šã•ã‚ŒãŸæ•°ã®ã‚­ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã—ã€ãã‚Œãã‚Œã®ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆã§è¿”ã™ãƒ¡ã‚½ãƒƒãƒ‰ã€‚

        Args:
            queues_num (int, optional): ç”Ÿæˆã™ã‚‹ã‚­ãƒ¥ãƒ¼ã®æ•°ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1ã€‚
            timeout (float, optional): ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹éš›ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯5ã€‚

        Returns:
            List[Generator[Any, None, None]]: å„ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã€‚
        """

        def queue_generator(q: Queue, timeout: float) -> Generator[Any, None, None]:
            """ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã€‚

            Args:
                q (Queue): ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚­ãƒ¥ãƒ¼ã€‚
                timeout (float): ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰ã€‚

            Yields:
                Any: ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã€‚
            """
            while True:
                try:
                    yield q.get(timeout=timeout)
                except Empty:
                    break

        self.queues = [Queue() for _ in range(queues_num)]  # ã‚­ãƒ¥ãƒ¼ã‚’æŒ‡å®šã•ã‚ŒãŸæ•°ã ã‘ç”Ÿæˆ
        return [queue_generator(q, timeout) for q in self.queues]  # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™


# åˆ©ç”¨å¯èƒ½ãªGPTãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
AVAILABLE_MODELS = {"gpt-3.5-turbo": 1024, "gpt-4": 512}
# APIã‚­ãƒ¼ã®è¨­å®š
openai.api_key = os.environ["OPENAI_API_KEY"]
USER_ID = "TESTID"
ASSISTANT_WARNING = (
    "æ³¨æ„ï¼šç§ã¯AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã€æƒ…å ±ãŒå¸¸ã«æœ€æ–°ã¾ãŸã¯æ­£ç¢ºã§ã‚ã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚é‡è¦ãªæ±ºå®šã‚’ã™ã‚‹å‰ã«ã¯ã€ä»–ã®ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
)

# %%
# Streamlitã‚¢ãƒ—ãƒªã®é–‹å§‹æ™‚ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–
if "id" not in st.session_state:
    logger.debug('session initialized')
    st.session_state['id'] = "{}_{:0>20}".format(USER_ID, int(time.time_ns()))
    # ã‚‚ã—USER_IDã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
    if not redisCliUserSetting.hexists(USER_ID, "model"):
        redisCliUserSetting.hset(USER_ID, "model", list(AVAILABLE_MODELS.keys())[0])
    # ã‚‚ã—USER_IDã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã€æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
    elif redisCliUserSetting.hget(USER_ID, "model").decode() not in AVAILABLE_MODELS:
        redisCliUserSetting.hset(USER_ID, "model", list(AVAILABLE_MODELS.keys())[0])
    

# éå»ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
# INPUT_MAX_TOKENS = 20

logger.debug(f'session_id first : {st.session_state.id}')

st.title("Streamlitã®ChatGPTã‚µãƒ³ãƒ—ãƒ«")

# å®šæ•°å®šç¾©


# Streamlitã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«åˆ©ç”¨å¯èƒ½ãªGPTãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ãŸã‚ã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¿½åŠ 
redisCliUserSetting.hset(
    USER_ID,
    "model",
    st.sidebar.selectbox(
        "GPTãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",  # GPTãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ãŸã‚ã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¡¨ç¤º
        AVAILABLE_MODELS,  # åˆ©ç”¨å¯èƒ½ãªGPTãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
        index=list(AVAILABLE_MODELS).index(  # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            redisCliUserSetting.hget(USER_ID, "model").decode()  # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        ),
    ),  # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
)
INPUT_MAX_TOKENS = AVAILABLE_MODELS[redisCliUserSetting.hget(USER_ID, "model").decode()]


# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã€ŒNew chatã€ãƒœã‚¿ãƒ³ã‚’è¿½åŠ ã—ã¾ã™ã€‚
# ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†å®Ÿè¡Œã—ã¾ã™ã€‚
if st.sidebar.button('ğŸ”„ New chat'):
    del st.session_state['id']
    st.rerun()

# 7æ—¥åˆ†ã®æ™‚é–“ã‚’æˆ»ã‚‹
seven_days_ago = datetime.datetime.now()
seven_days_ago_midnight = seven_days_ago.replace(
    hour=0, minute=0, second=0, microsecond=0
)
seven_days_ago_unixtime = int(seven_days_ago_midnight.timestamp())
session_id_with_chat_num_within_last_seven_days = redisCliAccessTime.zrangebyscore(
    "access", seven_days_ago_unixtime, "+inf"
)
session_id_within_last_seven_days = {
    "_".join(id_num.decode().split("_")[:-1])
    for id_num in session_id_with_chat_num_within_last_seven_days
}
user_chats = redisCliPastChat.hgetall(USER_ID)
user_chats_within_last_seven_days : dict = {
    session_id.decode(): json.loads(chat_data)
    for session_id, chat_data in user_chats.items()
    if session_id.decode() in session_id_within_last_seven_days
}

user_chats_within_last_seven_days_sorted : list[tuple] = sorted(
    user_chats_within_last_seven_days.items(), reverse=True
)

st.sidebar.markdown("<p style='font-size:20px; color:#FFFF00;'>éå»ã®ãƒãƒ£ãƒƒãƒˆ</p>", unsafe_allow_html=True)

for session_id, info in user_chats_within_last_seven_days_sorted:
    #print(info)
    title = info['title']
    if len(title) > 15:
        title = title[:15] + '...'
    if st.sidebar.button(title):
        # ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸå ´åˆã€session_idã‚’st.session_state.idã«ä»£å…¥
        st.session_state['id'] = session_id
        logger.debug(f'sessin id button : {st.session_state.id} clicked')
        # ç”»é¢ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
        st.rerun()

# ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‹ã‚‰ã®è­¦å‘Šã‚’è¼‰ã›ã‚‹
with st.chat_message("assistant"):
    st.write(ASSISTANT_WARNING)


# ä»¥å‰ã®ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’è¡¨ç¤º
for chat in redisCliPrompt.lrange(st.session_state.id, 0, -1):
    chat = json.loads(chat)
    with st.chat_message(chat["role"]):
        st.write(chat["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
user_msg: str = st.chat_input("ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›")

# å‡¦ç†é–‹å§‹
if user_msg:
    #logger.debug(f'session_id second : {st.session_state.id}')

    # æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    with st.chat_message("user"):
        st.write(user_msg)
    new_prompt: dict = {"role": "user", "content": user_msg}
    redisCliPrompt.rpush(st.session_state.id, json.dumps(new_prompt))
    error_flag = False
    try:
        # å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
        user_msg_tokens: int = calc_token_tiktoken(str([new_prompt]))
        logger.debug(f"å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {user_msg_tokens}")
        if user_msg_tokens > INPUT_MAX_TOKENS:
            # st.text_area("å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", user_msg, height=100)  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å†è¡¨ç¤º
            # st.warning("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé•·ã™ãã¾ã™ã€‚çŸ­ãã—ã¦ãã ã•ã„ã€‚" f"({user_msg_tokens}tokens)")
            raise Exception("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé•·ã™ãã¾ã™ã€‚çŸ­ãã—ã¦ãã ã•ã„ã€‚" f"({user_msg_tokens}tokens)")
        if check_rate_limit_exceed(
            redisCliAccessTime, key_name="access", late_limit=1, late_limit_period=1
        ):
            raise Exception("ã‚¢ã‚¯ã‚»ã‚¹æ•°ãŒå¤šã„ãŸã‚ã€æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚")
        prompt = [
                json.loads(prompt)
                for prompt in redisCliPrompt.lrange(st.session_state.id, 0, -1)
            ]
        response = response_chatgpt(prompt
            
        )
    except Exception as e:
        error_flag = True
        st.warning(e)
        # ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã®ã§ä»Šå›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤ã™ã‚‹
        redisCliPrompt.rpop(st.session_state.id, 1)
    if not error_flag:
        now = time.time()
        redisCliAccessTime.zadd(
            "access",
            {
                f"{st.session_state.id}_{redisCliPrompt.llen(st.session_state.id):0>6}": now
            },
        )

        def redisCliPastChatRecord(prompt, timestamp, model, session_id):
            logger.debug('redisCliPastChatRecord start')
            try:
                if not redisCliPastChat.hexists(USER_ID, session_id):
                    prompt_for_title = copy(prompt[0])
                    add_prompt = "\n\nã“ã®å†…å®¹ã«ç›¸å¿œã—ã„çŸ­ã„ã‚¿ã‚¤ãƒˆãƒ«ã‚’è€ƒãˆã€è‡ªèº«ã®ã‚ã‚Šãªã—ã«é–¢ã‚ã‚‰ãšã€å›ç­”ã¨ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã ã‘ã‚’'â—‹â—‹'ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
                    add_prompt_token_num = calc_token_tiktoken(add_prompt)

                    while True:
                        if (
                            INPUT_MAX_TOKENS
                            >= calc_token_tiktoken(str([prompt_for_title]))
                            + add_prompt_token_num
                        ):
                            break
                        prompt_for_title["content"] = prompt_for_title["content"][:-1]
                    prompt_for_title["content"] += add_prompt
                    logger.debug(f'prompt_for_title : {prompt_for_title}')
                    title = openai.ChatCompletion.create(
                        model=model, messages=[prompt_for_title], stream=False
                    )["choices"][0]['message'].get("content", "")
                else:
                    title = json.loads(redisCliPastChat.hget(USER_ID, session_id))[
                        "title"
                    ]
                logger.debug(f'redisCliPastChat hset USER_ID:{USER_ID}')
                logger.debug(f'session_id:{session_id}')
                logger.debug(f'timestamp:{timestamp}')
                logger.debug(f'model:{model}')
                logger.debug(f'title:{title}')
                redisCliPastChat.hset(
                    USER_ID,
                    session_id,
                    json.dumps({"timestamp": timestamp, "model": model, "title": title}),
                )
            except:
                traceback.print_exc()

        executor1.submit(
            redisCliPastChatRecord,
            prompt,
            now,
            redisCliUserSetting.hget(USER_ID, "model").decode(),
            st.session_state.id
        )

        assistant_prompt = {"role": "assistant", "content": ""}
        redisCliPrompt.rpush(st.session_state.id, json.dumps(assistant_prompt))
        prompt_length = redisCliPrompt.llen(st.session_state.id)

        with st.chat_message("assistant"):
            assistant_msg = ""
            assistant_response_area = st.empty()
            for chunk in response:
                # å›ç­”ã‚’é€æ¬¡è¡¨ç¤º
                tmp_assistant_msg = chunk["choices"][0]["delta"].get("content", "")
                assistant_msg += tmp_assistant_msg
                assistant_prompt["content"] = assistant_msg
                redisCliPrompt.lset(
                    st.session_state.id, prompt_length - 1, json.dumps(assistant_prompt)
                )
                assistant_response_area.write(assistant_msg)
        logger.debug('Rerun')
        st.rerun()

    # å‡¦ç†çµ‚äº†


# %%
